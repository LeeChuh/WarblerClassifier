{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-05T15:59:03.968136Z","iopub.status.busy":"2023-07-05T15:59:03.967774Z","iopub.status.idle":"2023-07-05T15:59:13.772345Z","shell.execute_reply":"2023-07-05T15:59:13.771321Z","shell.execute_reply.started":"2023-07-05T15:59:03.968104Z"},"trusted":true},"outputs":[],"source":["import warnings\n","from sklearn.exceptions import ConvergenceWarning\n","warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=UserWarning)\n","\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import os\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","from sklearn.metrics import classification_report, f1_score , confusion_matrix\n","\n","\n","\n","# Tensorflow Libraries\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.layers import Dense, Dropout , BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import layers,models,Model\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers.experimental import preprocessing\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras import mixed_precision\n","mixed_precision.set_global_policy('mixed_float16')\n","\n","\n","print(tf.__version__)"]},{"cell_type":"markdown","metadata":{},"source":["# Loading Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-05T15:59:25.553181Z","iopub.status.busy":"2023-07-05T15:59:25.552023Z","iopub.status.idle":"2023-07-05T15:59:50.902096Z","shell.execute_reply":"2023-07-05T15:59:50.901133Z","shell.execute_reply.started":"2023-07-05T15:59:25.553138Z"},"trusted":true},"outputs":[],"source":["dataset = {\n","             \"train_data\" : \"/Users/chuhanli/Desktop/birdData/train\",\n","             \"valid_data\" : \"/Users/chuhanli/Desktop/birdData/valid\",\n","             \"test_data\" : \"/Users/chuhanli/Desktop/birdData/test\"\n","          }\n","\n","all_data = []\n","for path in dataset.values():\n","    data = {\"imgpath\": [] , \"labels\": [] }\n","    category = os.listdir(path)\n","\n","    for folder in category:\n","        if folder == '.DS_Store':\n","            continue\n","        folderpath = os.path.join(path , folder)\n","        filelist = os.listdir(folderpath)\n","        for file in filelist:\n","            fpath = os.path.join(folderpath, file)\n","            data[\"imgpath\"].append(fpath)\n","            data[\"labels\"].append(folder)\n","        \n","        \n","    all_data.append(data.copy())\n","    data.clear()\n","\n","    \n","    \n","train_df = pd.DataFrame(all_data[0] , index=range(len(all_data[0]['imgpath'])))\n","valid_df = pd.DataFrame(all_data[1] , index=range(len(all_data[1]['imgpath'])))\n","test_df = pd.DataFrame(all_data[2] , index=range(len(all_data[2]['imgpath'])))\n","\n","\n","# #Convert labels to numbers\n","lb = LabelEncoder()\n","train_df['encoded_labels'] = lb.fit_transform(train_df['labels'])\n","valid_df['encoded_labels'] = lb.fit_transform(valid_df['labels'])\n","test_df['encoded_labels'] = lb.fit_transform(test_df['labels'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-05T16:00:17.269612Z","iopub.status.busy":"2023-07-05T16:00:17.268938Z","iopub.status.idle":"2023-07-05T16:00:22.942062Z","shell.execute_reply":"2023-07-05T16:00:22.940629Z","shell.execute_reply.started":"2023-07-05T16:00:17.269577Z"},"trusted":true},"outputs":[],"source":["train  = train_df[\"labels\"].value_counts()\n","label = train.tolist()\n","index = train.index.tolist()\n","\n","colors = [\n","    \"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\",\n","    \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\",\n","    \"#aec7e8\", \"#ffbb78\", \"#98df8a\", \"#ff9896\", \"#c5b0d5\",\n","    \"#c49c94\", \"#f7b6d2\", \"#c7c7c7\", \"#dbdb8d\", \"#9edae5\",\n","    \"#5254a3\", \"#6b6ecf\", \"#bdbdbd\", \"#8ca252\", \"#bd9e39\",\n","    \"#ad494a\", \"#8c6d31\", \"#6b6ecf\", \"#e7ba52\", \"#ce6dbd\",\n","    \"#9c9ede\", \"#cedb9c\", \"#de9ed6\", \"#ad494a\", \"#d6616b\",\n","    \"#f7f7f7\", \"#7b4173\", \"#a55194\", \"#ce6dbd\"\n","]\n","\n","\n","\n","plt.figure(figsize=(30,30))\n","plt.title(\"Training data images count per class\",fontsize=38)\n","plt.xlabel('Number of images', fontsize=35)\n","plt.ylabel('Classes', fontsize=35)\n","plt.barh(index,label, color=colors)\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-05T16:00:33.011127Z","iopub.status.busy":"2023-07-05T16:00:33.010726Z","iopub.status.idle":"2023-07-05T16:00:33.033993Z","shell.execute_reply":"2023-07-05T16:00:33.033042Z","shell.execute_reply.started":"2023-07-05T16:00:33.011087Z"},"trusted":true},"outputs":[],"source":["train_df.sample(n=15, random_state=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-05T16:00:36.310711Z","iopub.status.busy":"2023-07-05T16:00:36.310002Z","iopub.status.idle":"2023-07-05T16:00:36.331695Z","shell.execute_reply":"2023-07-05T16:00:36.330653Z","shell.execute_reply.started":"2023-07-05T16:00:36.310677Z"},"trusted":true},"outputs":[],"source":["print(\"----------Train-------------\")\n","print(train_df[[\"imgpath\", \"labels\"]].head(5))\n","print(train_df.shape)\n","print(\"--------Validation----------\")\n","print(valid_df[[\"imgpath\", \"labels\"]].head(5))\n","print(valid_df.shape)\n","print(\"----------Test--------------\")\n","print(test_df[[\"imgpath\", \"labels\"]].head(5))\n","print(test_df.shape)"]},{"cell_type":"markdown","metadata":{},"source":["# Show sample from data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-05T16:00:38.814022Z","iopub.status.busy":"2023-07-05T16:00:38.813669Z","iopub.status.idle":"2023-07-05T16:00:40.720701Z","shell.execute_reply":"2023-07-05T16:00:40.719852Z","shell.execute_reply.started":"2023-07-05T16:00:38.813993Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(15,12))\n","for i, row in valid_df.sample(n=16).reset_index().iterrows():\n","    plt.subplot(4,4,i+1)\n","    image_path = row['imgpath']\n","    image = Image.open(image_path)\n","    plt.imshow(image)\n","    plt.title(row[\"labels\"])\n","    plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Creating Dataloaders"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-05T16:00:56.414612Z","iopub.status.busy":"2023-07-05T16:00:56.414223Z","iopub.status.idle":"2023-07-05T16:01:37.247101Z","shell.execute_reply":"2023-07-05T16:01:37.246125Z","shell.execute_reply.started":"2023-07-05T16:00:56.414563Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 35\n","IMAGE_SIZE = (224, 224)\n","\n","\n","generator = ImageDataGenerator(\n","    preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n","    # there could be image augmentation here\n",")\n","\n","# Split the data into three categories.\n","train_images = generator.flow_from_dataframe(\n","    dataframe=train_df,\n","    x_col='imgpath',\n","    y_col='labels',\n","    target_size=IMAGE_SIZE,\n","    color_mode='rgb',\n","    class_mode='categorical',\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    seed=42,\n",")\n","\n","val_images = generator.flow_from_dataframe(\n","    dataframe=valid_df,\n","    x_col='imgpath',\n","    y_col='labels',\n","    target_size=IMAGE_SIZE,\n","    color_mode='rgb',\n","    class_mode='categorical',\n","    batch_size=BATCH_SIZE,\n","    shuffle=False\n",")\n","\n","test_images = generator.flow_from_dataframe(\n","    dataframe=test_df,\n","    x_col='imgpath',\n","    y_col='labels',\n","    target_size=IMAGE_SIZE,\n","    color_mode='rgb',\n","    class_mode='categorical',\n","    batch_size=BATCH_SIZE,\n","    shuffle=False\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Model Structure"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-05T16:01:40.227324Z","iopub.status.busy":"2023-07-05T16:01:40.22659Z","iopub.status.idle":"2023-07-05T16:01:49.975636Z","shell.execute_reply":"2023-07-05T16:01:49.974648Z","shell.execute_reply.started":"2023-07-05T16:01:40.22729Z"},"trusted":true},"outputs":[],"source":["# Load the pretained model\n","pretrained_model = tf.keras.applications.EfficientNetB5(\n","    input_shape=(224, 224, 3),\n","    include_top=False, # we don`t need a pre-trained top layer (output layer)\n","    weights='imagenet',\n","    pooling='max'\n",")\n","\n","# Freezing the layers of a pretrained neural network\n","for i, layer in enumerate(pretrained_model.layers):\n","    pretrained_model.layers[i].trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-05T16:02:45.702715Z","iopub.status.busy":"2023-07-05T16:02:45.70234Z","iopub.status.idle":"2023-07-05T16:02:48.329123Z","shell.execute_reply":"2023-07-05T16:02:48.327944Z","shell.execute_reply.started":"2023-07-05T16:02:45.702684Z"},"trusted":true},"outputs":[],"source":["num_classes = len(set(train_images.classes))\n","\n","\n","# Data Augmentation Step\n","augment = tf.keras.Sequential([\n","  layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n","  layers.experimental.preprocessing.RandomRotation(0.15),\n","  layers.experimental.preprocessing.RandomZoom(0.12),\n","  layers.experimental.preprocessing.RandomContrast(0.12),\n","], name='AugmentationLayer')\n","\n","\n","inputs = layers.Input(shape = (224,224,3), name='inputLayer')\n","x = augment(inputs)\n","pretrain_out = pretrained_model(x, training = False)\n","x = layers.Dense(1024)(pretrain_out)\n","x = layers.Activation(activation=\"relu\")(x) \n","x = BatchNormalization()(x)\n","x = layers.Dropout(0.45)(x)\n","x = layers.Dense(512)(x)\n","x = layers.Activation(activation=\"relu\")(x) \n","x = BatchNormalization()(x)\n","x = layers.Dropout(0.3)(x)\n","x = layers.Dense(num_classes)(x)\n","outputs = layers.Activation(activation=\"softmax\", dtype=tf.float32, name='activationLayer')(x) # mixed_precision need separated Dense and Activation layers\n","model = Model(inputs=inputs, outputs=outputs)\n","\n","\n","\n","model.compile(\n","    optimizer=Adam(0.0005),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","print(model.summary())"]},{"cell_type":"markdown","metadata":{},"source":["# Training : Transfer Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-05T16:03:23.490031Z","iopub.status.busy":"2023-07-05T16:03:23.489666Z","iopub.status.idle":"2023-07-05T16:58:11.126924Z","shell.execute_reply":"2023-07-05T16:58:11.125617Z","shell.execute_reply.started":"2023-07-05T16:03:23.490002Z"},"trusted":true},"outputs":[],"source":["history = model.fit(\n","    train_images,\n","    steps_per_epoch=len(train_images),\n","    validation_data=val_images,\n","    validation_steps=len(val_images),\n","    epochs=10,\n","    callbacks=[\n","        EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n","                               patience = 3,\n","                               restore_best_weights = True), \n","        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min') \n","    ]\n",")\n","model.save_weights('./checkpoints/my_checkpoint')"]},{"cell_type":"markdown","metadata":{},"source":["# Display model performance"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-05T16:58:13.798167Z","iopub.status.busy":"2023-07-05T16:58:13.797528Z","iopub.status.idle":"2023-07-05T16:58:14.43213Z","shell.execute_reply":"2023-07-05T16:58:14.431189Z","shell.execute_reply.started":"2023-07-05T16:58:13.798134Z"},"trusted":true},"outputs":[],"source":["# Define needed variables\n","tr_acc = history.history['accuracy']\n","tr_loss = history.history['loss']\n","val_acc = history.history['val_accuracy']\n","val_loss = history.history['val_loss']\n","index_loss = np.argmin(val_loss)\n","val_lowest = val_loss[index_loss]\n","index_acc = np.argmax(val_acc)\n","acc_highest = val_acc[index_acc]\n","Epochs = [i+1 for i in range(len(tr_acc))]\n","loss_label = f'best epoch= {str(index_loss + 1)}'\n","acc_label = f'best epoch= {str(index_acc + 1)}'\n","\n","# Plot training history\n","plt.figure(figsize= (20, 8))\n","plt.style.use('fivethirtyeight')\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n","plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n","plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n","plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n","plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.tight_layout\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Training : Fine Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-05T17:00:06.902053Z","iopub.status.busy":"2023-07-05T17:00:06.901126Z"},"trusted":true},"outputs":[],"source":["pretrained_model.trainable = True\n","for layer in pretrained_model.layers:\n","    if isinstance(layer, layers.BatchNormalization): # set BatchNorm layers as not trainable\n","        layer.trainable = False\n","        \n","# let`s see first 10 layers\n","for l in pretrained_model.layers[:10]:\n","    print(l.name, l.trainable)\n","\n","model.compile(\n","    optimizer=Adam(0.00001), # fine tuning requires very little learning rate\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","# model.load_weights('./checkpoints/my_checkpoint')\n","print(model.summary())\n","history = model.fit(\n","    train_images,\n","    steps_per_epoch=len(train_images),\n","    validation_data=val_images,\n","    validation_steps=len(val_images),\n","    epochs=20,\n","    callbacks=[\n","        EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n","                               patience = 5,\n","                               restore_best_weights = True), # if val loss decreases for 5 epochs in a row, stop training,\n","        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min') \n","    ]\n",")\n","model.save_weights('./checkpoints/my_checkpoint')"]},{"cell_type":"markdown","metadata":{},"source":["# Display model performance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define needed variables\n","tr_acc = history.history['accuracy']\n","tr_loss = history.history['loss']\n","val_acc = history.history['val_accuracy']\n","val_loss = history.history['val_loss']\n","index_loss = np.argmin(val_loss)\n","val_lowest = val_loss[index_loss]\n","index_acc = np.argmax(val_acc)\n","acc_highest = val_acc[index_acc]\n","Epochs = [i+1 for i in range(len(tr_acc))]\n","loss_label = f'best epoch= {str(index_loss + 1)}'\n","acc_label = f'best epoch= {str(index_acc + 1)}'\n","\n","# Plot training history\n","plt.figure(figsize= (20, 8))\n","plt.style.use('fivethirtyeight')\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n","plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n","plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n","plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n","plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.tight_layout\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# model.evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results = model.evaluate(test_images, verbose=0)\n","\n","print(\"    Test Loss: {:.5f}\".format(results[0]))\n","print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"]},{"cell_type":"markdown","metadata":{},"source":["# F1 Score / Recall / Precision"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_true = test_images.classes\n","y_pred = np.argmax(model.predict(test_images), axis = 1)\n","f1 = f1_score(y_true, y_pred, average='macro')\n","print(\"F1 Score:\", f1)\n","print(classification_report(y_true, y_pred, target_names=test_images.class_indices.keys()))"]},{"cell_type":"markdown","metadata":{},"source":["# Get Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["classes = dict(zip(test_images.class_indices.values(), test_images.class_indices.keys()))\n","Predictions = pd.DataFrame({\"Image Index\" : list(range(len(test_images.labels))), \n","                            \"Test Labels\" : test_images.labels, \n","                            \"Test Classes\" : [classes[i] for i in test_images.labels],\n","                            \"Prediction Labels\" : y_pred,\n","                            \"Prediction Classes\" : [classes[i] for i in y_pred],\n","                            \"Path\": test_images.filenames,\n","                            \"Prediction Probability\" : [x for x in np.asarray(tf.reduce_max(model.predict(test_images), axis = 1))]\n","                           })\n","Predictions.head(8)"]},{"cell_type":"markdown","metadata":{},"source":["# Print the most confident errors"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(20,20))\n","for i, row in Predictions[Predictions[\"Test Labels\"] != Predictions[\"Prediction Labels\"]].sort_values(\"Prediction Probability\").tail(20).reset_index().iterrows():\n","    plt.subplot(5,4,i+1)\n","    image_path = row['Path']\n","    image = Image.open(image_path)\n","    plt.imshow(image)\n","    plt.title(f'TRUE: {row[\"Test Classes\"]} | PRED: {row[\"Prediction Classes\"]}', fontsize=8)\n","    plt.axis('off')\n","    \n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Confusion Matrics and Classification Report"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["preds = model.predict_generator(test_images)\n","y_pred = np.argmax(preds, axis=1)\n","g_dict = test_images.class_indices\n","classes = list(g_dict.keys())\n","\n","# Confusion matrix\n","cm = confusion_matrix(test_images.classes, y_pred)\n","\n","plt.figure(figsize= (30, 30))\n","plt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\n","plt.title('Confusion Matrix')\n","plt.colorbar()\n","\n","tick_marks = np.arange(len(classes))\n","plt.xticks(tick_marks, classes, rotation= 45)\n","plt.yticks(tick_marks, classes)\n","\n","\n","thresh = cm.max() / 2.\n","for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n","\n","plt.tight_layout()\n","plt.ylabel('True Label')\n","plt.xlabel('Predicted Label')\n","\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
